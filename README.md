# Gesture_recog_py
 sign language recomendation system for deaf and dumb people
## ğŸ–ğŸ™ HoloSign â€“ Real-Time Emergency & Medical Assistance System

**HoloSign** is an innovative, real-time emergency response system designed to assist individuals in distress through intuitive gesture recognition, voice commands, and automated health alerts. Built with a clean, user-friendly interface, the system integrates multiple modules to enhance accessibility and ensure rapid response in critical situations.

### ğŸ”§ Key Features:

1. **ğŸ“¸ Real-Time Gesture Detection**

   * Utilizes a live camera to monitor hand gestures.
   * Detects predefined emergency gestures to automatically trigger alerts.
   * Initiates emergency protocols, including phone calls and alert sounds, without the need for verbal communication.

2. **ğŸ™ Voice Assistant**

   * Allows users to issue emergency commands using voice input.
   * Ideal for scenarios where gesture-based control is not possible.
   * "Tap to Speak" interface ensures simple and quick activation.

3. **ğŸ’¬ Emergency Chat**

   * Enables users to send instant text-based emergency messages.
   * Useful for silent communication during medical or safety emergencies.
   * Features a clean and resettable chat interface.

4. **ğŸ©º Health Check-In**

   * Collects key health vitals: blood pressure, blood sugar, and cholesterol levels.
   * Allows users to monitor and log their health status.
   * Provides context to emergency responders for faster assessment.

5. **ğŸ“„ Emergency Prompts**

   * Offers pre-defined emergency messages for quick dispatch.
   * Simplifies communication when time is critical or the user is unable to type or speak.

### âš™ï¸ Automation Highlights:

* **Automatic Phone Calls**: Triggered upon detecting a distress gesture.
* **Alert Sound Activation**: Loud alerts are played automatically to draw attention and signal urgency.

---

### ğŸŒ Deployment:

The system is built and tested on `localhost:8501`, implying it's developed using frameworks like **Streamlit** for real-time web-based interactivity.

---

This project exemplifies a practical blend of AI, computer vision, and assistive technology aimed at improving emergency responsiveness and personal safety, especially for individuals with communication limitations or medical conditions.


<img width="1855" height="961" alt="Screenshot 2025-07-27 002626" src="https://github.com/user-attachments/assets/63b9a8da-b824-4011-b40e-c5b3a919c6d6" />
<img width="1845" height="890" alt="Screenshot 2025-07-27 002637" src="https://github.com/user-attachments/assets/ef5eea67-6892-48ce-914d-6b7ce3ad499c" />
<img width="1845" height="890" alt="Screenshot 2025-07-27 002646" src="https://github.com/user-attachments/assets/bca34fcb-a740-4e9a-b080-f2195c68e759" />
<img width="1845" height="890" alt="Screenshot 2025-07-27 002656" src="https://github.com/user-attachments/assets/946e45bf-7c19-478c-bc6a-2202d4bdf86a" />
<img width="1845" height="890" alt="Screenshot 2025-07-27 002709" src="https://github.com/user-attachments/assets/c85632cd-39f1-4637-b457-4bf048bef575" />
